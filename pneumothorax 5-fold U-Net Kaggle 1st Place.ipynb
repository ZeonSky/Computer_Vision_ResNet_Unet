{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine suddenly gasping for air, helplessly breathless for no apparent reason. Could it be a collapsed lung? In the future, your entry in this competition could predict the answer.\n",
    "\n",
    "# Pneumothorax can be caused by a blunt chest injury, damage from underlying lung disease, or most horrifying—it may occur for no obvious reason at all. On some occasions, a collapsed lung can be a life-threatening event.\n",
    "\n",
    "# Pneumothorax is usually diagnosed by a radiologist on a chest x-ray, and can sometimes be very difficult to confirm. An accurate AI algorithm to detect pneumothorax would be useful in a lot of clinical scenarios. AI could be used to triage chest radiographs for priority interpretation, or to provide a more confident diagnosis for non-radiologists.\n",
    "\n",
    "# The Society for Imaging Informatics in Medicine (SIIM) is the leading healthcare organization for those interested in the current and future use of informatics in medical imaging. Their mission is to advance medical imaging informatics across the enterprise through education, research, and innovation in a multi-disciplinary community. Today, they need your help.\n",
    "\n",
    "# In this competition, you’ll develop a model to classify (and if present, segment) pneumothorax from a set of chest radiographic images. If successful, you could aid in the early recognition of pneumothoraces and save lives.\n",
    "\n",
    "# If you’re up for the challenge, take a deep breath, and get started now.\n",
    "\n",
    "# Note: As specified on the Data Page, the dataset must be retrieved from Cloud Healthcare. Review this tutorial (or in pdf format) for instructions on how to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicating Kaggle 1st place result from @Anuar Aimoldin\n",
    "\n",
    "Credit: fast.ai, Anuar Aimoldin\n",
    "\n",
    "https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation\n",
    "\n",
    "# Kernel guideline\n",
    "\n",
    "### Version 2 - start here\n",
    "* Image size 128x128\n",
    "* Unet with pretrained resnet34 encoder\n",
    "* Best threshold selection\n",
    "* Output visualization\n",
    "* Total run time of about 34 minutes\n",
    "\n",
    "### Version 3 - 5-fold ensemble\n",
    "* Example of 5-fold ensemble using sklearn KFold function, based on version 2\n",
    "* Changed learning rates\n",
    "* Total run time of about 132 minutes\n",
    "\n",
    "### Version 4 - 256x256 \n",
    "* Based on version 2 but with images of size 256x256\n",
    "* Batch size reduced to 32\n",
    "\n",
    "### Where to go next?\n",
    "* Look at as many examples as you can and try to understand why the model fails when it does;\n",
    "* There are several ways to convert a 1024x1024 to a lower resolution (e.g., bilinear, nearest), some may be more appropriate to this competition than others;\n",
    "* Progressive rescaling (start with small images like 64x64, train, save the weights, increase to 128x128, train with previous weights, and so on);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../input/siim-acr-pneumothorax-segmentation')\n",
    "\n",
    "import fastai\n",
    "from fastai.vision import *\n",
    "from mask_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 256\n",
    "path = Path(f'../input/pneumotorax{SZ}/data{SZ}/data{SZ}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# copy pretrained weights for resnet34 to the folder fastai will search by default\n",
    "Path('/tmp/.cache/torch/checkpoints/').mkdir(exist_ok=True, parents=True)\n",
    "!cp '../input/resnet34/resnet34.pth' '/tmp/.cache/torch/checkpoints/resnet34-333f7ec4.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Setting div=True in open_mask\n",
    "class SegmentationLabelList(SegmentationLabelList):\n",
    "    def open(self, fn): return open_mask(fn, div=True)\n",
    "    \n",
    "class SegmentationItemList(SegmentationItemList):\n",
    "    _label_cls = SegmentationLabelList\n",
    "\n",
    "# Setting transformations on masks to False on test set\n",
    "def transform(self, tfms:Optional[Tuple[TfmList,TfmList]]=(None,None), **kwargs):\n",
    "    if not tfms: tfms=(None,None)\n",
    "    assert is_listy(tfms) and len(tfms) == 2\n",
    "    self.train.transform(tfms[0], **kwargs)\n",
    "    self.valid.transform(tfms[1], **kwargs)\n",
    "    kwargs['tfm_y'] = False # Test data has no labels\n",
    "    if self.test: self.test.transform(tfms[1], **kwargs)\n",
    "    return self\n",
    "fastai.data_block.ItemLists.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create databunch\n",
    "data = (SegmentationItemList.from_folder(path=path/'train')\n",
    "        .split_by_rand_pct(0.2)\n",
    "        .label_from_func(lambda x : str(x).replace('train', 'masks'), classes=[0, 1])\n",
    "        .add_test((path/'test').ls(), label=None)\n",
    "        .transform(get_transforms(), size=SZ, tfm_y=True)\n",
    "        .databunch(path=Path('.'), bs=32)\n",
    "        .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some images with masks\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create U-Net with a pretrained resnet34 as encoder\n",
    "learn = unet_learner(data, models.resnet34, metrics=[dice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit one cycle of 6 epochs with max lr of 1e-3\n",
    "learn.fit_one_cycle(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the encoder (resnet34)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit one cycle of 12 epochs\n",
    "lr = 1e-3\n",
    "learn.fit_one_cycle(12, slice(lr/30, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for the validation set\n",
    "preds, ys = learn.get_preds()\n",
    "preds = preds[:,1,...]\n",
    "ys = ys.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_overall(preds, targs):\n",
    "    n = preds.shape[0]\n",
    "    preds = preds.view(n, -1)\n",
    "    targs = targs.view(n, -1)\n",
    "    intersect = (preds * targs).sum(-1).float()\n",
    "    union = (preds+targs).sum(-1).float()\n",
    "    u0 = union==0\n",
    "    intersect[u0] = 1\n",
    "    union[u0] = 2\n",
    "    return (2. * intersect / union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal threshold\n",
    "dices = []\n",
    "thrs = np.arange(0.01, 1, 0.01)\n",
    "for i in progress_bar(thrs):\n",
    "    preds_m = (preds>i).long()\n",
    "    dices.append(dice_overall(preds_m, ys).mean())\n",
    "dices = np.array(dices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dice = dices.max()\n",
    "best_thr = thrs[dices.argmax()]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(thrs, dices)\n",
    "plt.vlines(x=best_thr, ymin=dices.min(), ymax=dices.max())\n",
    "plt.text(best_thr+0.03, best_dice-0.01, f'DICE = {best_dice:.3f}', fontsize=14);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some samples\n",
    "rows = 10\n",
    "plot_idx = ys.sum((1,2)).sort(descending=True).indices[:rows]\n",
    "for idx in plot_idx:\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(12, 4))\n",
    "    ax0.imshow(data.valid_ds[idx][0].data.numpy().transpose(1,2,0))\n",
    "    ax1.imshow(ys[idx], vmin=0, vmax=1)\n",
    "    ax2.imshow(preds[idx], vmin=0, vmax=1)\n",
    "    ax1.set_title('Targets')\n",
    "    ax2.set_title('Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for test set\n",
    "preds, _ = learn.get_preds(ds_type=DatasetType.Test)\n",
    "preds = (preds[:,1,...]>best_thr).long().numpy()\n",
    "print(preds.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate rle encodings (images are first converted to the original size)\n",
    "rles = []\n",
    "for p in progress_bar(preds):\n",
    "    im = PIL.Image.fromarray((p.T*255).astype(np.uint8)).resize((1024,1024))\n",
    "    im = np.asarray(im)\n",
    "    rles.append(mask2rle(im, 1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [o.stem for o in data.test_ds.items]\n",
    "sub_df = pd.DataFrame({'ImageId': ids, 'EncodedPixels': rles})\n",
    "sub_df.loc[sub_df.EncodedPixels=='', 'EncodedPixels'] = '-1'\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
